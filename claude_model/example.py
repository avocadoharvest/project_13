"""
m4aíŒŒì¼ì„ ì½ì–´ì™€ì„œ textë¡œ ë§Œë“¤ì–´ ì£¼ê¸°
"""

# import whisper

# # ëª¨ë¸ ë¡œë“œ (tiny, base, small, medium, large ì¤‘ ì„ íƒ ê°€ëŠ¥. í´ìˆ˜ë¡ ì •í™•ë„â†‘ ì†ë„â†“)
# model = whisper.load_model("base")  # ê°€ì¥ ì¼ë°˜ì 

# # ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬
# result = model.transcribe("blossom.m4a", language="en", fp16=False)  # ì–¸ì–´ ë° fp16 ì˜µì…˜(ê¶Œì¥)
# print(result["text"])


## ë§ˆì´í¬ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ ë§Œë“¤ê¸°
# import speech_recognition as sr
# import whisper

# model = whisper.load_model("base")
# r = sr.Recognizer()
# with sr.Microphone(sample_rate=16000) as source:
#     print("ë§ì”€í•˜ì„¸ìš”...")
#     audio = r.listen(source)
#     # ìŒì„± ë°ì´í„° íŒŒì¼ë¡œ ì €ì¥í•´ë„ ê°€ëŠ¥
#     data = audio.get_wav_data()
#     # Whisperì—ì„œ ë°”ë¡œ NumPy ë°°ì—´ë¡œ ë³€í™˜
#     import numpy as np
#     wav = np.frombuffer(data, np.int16).astype(np.float32) / 32768.0
#     result = model.transcribe(wav, language='en', fp16=False)
#     print(result['text'])

### example.py
# import speech_recognition as sr
# import whisper
# import numpy as np

# def speech_to_text():
#     model = whisper.load_model("base")
#     r = sr.Recognizer()
#     with sr.Microphone(sample_rate=16000) as source:
#         print("ë§ì”€í•˜ì„¸ìš”...")
#         audio = r.listen(source)
#         data = audio.get_wav_data()
#         wav = np.frombuffer(data, np.int16).astype(np.float32) / 32768.0
#         result = model.transcribe(wav, language='en', fp16=False)
#         print(result['text'])
#         return result['text']


##################################ìµœì¢… ì „
# import speech_recognition as sr
# import whisper
# import numpy as np

# def speech_to_text():
#     model = whisper.load_model("base")
#     r = sr.Recognizer()
#     with sr.Microphone(sample_rate=16000) as source:
#         print("ë§ì”€í•˜ì„¸ìš”...")
#         audio = r.listen(source)
#         data = audio.get_wav_data()
#         wav = np.frombuffer(data, np.int16).astype(np.float32) / 32768.0
#         result = model.transcribe(wav, language='en', fp16=False)
#         print("ğŸ“ ì¸ì‹ëœ ë‹µë³€: ", result['text'])
#         return result['text']


import sounddevice as sd
import numpy as np
import whisper
import time
import sys

def speech_to_text(seconds=15, samplerate=16000):
    print(f"ğŸ¤ {seconds}ì´ˆ ë™ì•ˆ ë…¹ìŒí•©ë‹ˆë‹¤. (ìë™ ì¢…ë£Œ)")
    print("5ì´ˆ ë’¤ ì‹œì‘...")
    time.sleep(5)
    print("ë…¹ìŒ ì‹œì‘!")
    start_time = time.time()
    # ì‹¤ì‹œê°„ ê²½ê³¼ í‘œì‹œìš© ìŠ¤ë ˆë“œ
    stop = [False]
    def print_elapsed():
        while not stop[0]:
            elapsed = int(time.time() - start_time)
            sys.stdout.write(f"\râ±ï¸ ë…¹ìŒ ì¤‘... {elapsed}ì´ˆ ê²½ê³¼")
            sys.stdout.flush()
            time.sleep(0.2)
    import threading
    t = threading.Thread(target=print_elapsed)
    t.start()
    
    audio = sd.rec(int(samplerate * seconds), samplerate=samplerate, channels=1, dtype='int16')
    sd.wait()
    stop[0] = True
    t.join()
    print()  # ê°œí–‰

    wav = audio.flatten().astype(np.float32) / 32768.0
    model = whisper.load_model("base")
    result = model.transcribe(wav, language='en', fp16=False)
    print("ğŸ“ ì¸ì‹ëœ ë‹µë³€:", result['text'])
    return result['text']

# ì‚¬ìš© ì˜ˆì‹œ
# speech_to_text_strict(10)

