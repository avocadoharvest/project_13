from dotenv import load_dotenv
load_dotenv()

import os
import torch
from transformers import pipeline
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import HuggingFacePipeline
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from example import speech_to_text
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from gtts import gTTS
import playsound

def build_custom_rag_chain(retriever, prompt, model_name="microsoft/DialoGPT-large"):
    print(f"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # í† í° ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•œ íŒŒì´í”„ë¼ì¸ ì„¤ì •
    hf_pipeline = pipeline(
        "text-generation",
        model=model_name,
        tokenizer=model_name,
        max_length=1000,           # ìµœëŒ€ ê¸¸ì´ë¥¼ 1000ìœ¼ë¡œ ì œí•œ
        max_new_tokens=200,        # ìƒˆë¡œ ìƒì„±í•  í† í°ë§Œ 200ê°œë¡œ ì œí•œ
        truncation=True,           # ì…ë ¥ì´ ê¸¸ë©´ ìë™ìœ¼ë¡œ ìë¦„
        do_sample=False,
        device=0 if torch.cuda.is_available() else -1,
        pad_token_id=50256
    )
    
    llm = HuggingFacePipeline(pipeline=hf_pipeline)
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    
    def rag_chain(inputs):
        question = inputs["question"]
        answer = inputs["answer"]
        
        # ë¬¸ì„œ ê²€ìƒ‰
        search_query = f"{question} {answer}"
        docs = retriever.invoke(search_query)
        
        # Context ê¸¸ì´ ì œí•œ (í† í° ì ˆì•½)
        context = "\n\n".join([doc.page_content[:200] for doc in docs[:2]])  # ë¬¸ì„œ 2ê°œ, ê°ê° 200ìë¡œ ì œí•œ
        
        # ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ ì²´í¬ ë° ì œí•œ
        full_input = f"ì°¸ê³ ë¬¸ì„œ: {context}\në¬¸ì œ: {question[:100]}\në‹µë³€: {answer[:100]}"  # ê°ê° ê¸¸ì´ ì œí•œ
        
        try:
            result = llm_chain.invoke({
                "context": context,
                "question": question[:100],  # ë¬¸ì œë„ 100ìë¡œ ì œí•œ
                "answer": answer[:100]       # ë‹µë³€ë„ 100ìë¡œ ì œí•œ
            })
            
            if isinstance(result, dict) and 'text' in result:
                return result['text']
            else:
                return str(result)
                
        except Exception as e:
            print(f"LLM ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return "í‰ê°€ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ëª¨ë¸ ì˜¤ë¥˜"
    
    return rag_chain


def load_vectorstore():
    """ì €ì¥ëœ FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    db_path = "./db/faiss"
    
    if not os.path.exists(db_path):
        print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("ë¨¼ì € create_db.pyë¥¼ ì‹¤í–‰í•´ì„œ DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return None
    
    print("ğŸ” ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘...")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    print("âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì™„ë£Œ!")
    
    return vectorstore

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    vectorstore = load_vectorstore()
    if vectorstore is None:
        return
    
    retriever = vectorstore.as_retriever()
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì˜ë¬¸ ë…í•´ ì‹œí—˜ì˜ í‰ê°€ìì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ˜í—˜ìƒì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ë¬¸ì œ: {question}
ìˆ˜í—˜ìƒ ë‹µë³€: {answer}

í‰ê°€ ê¸°ì¤€:
1. ìˆ˜í—˜ìƒì´ ì •ë‹µì— ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€
2. ë…¼ë¦¬ì  ê·¼ê±°ê°€ ì •í™•í•œì§€  
3. ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì˜ ë°˜ì˜í–ˆëŠ”ì§€

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
ì ìˆ˜: [1~5ì , ì†Œìˆ˜ì  ê°€ëŠ¥]
í”¼ë“œë°±: [í•œê¸€ë¡œ êµ¬ì²´ì ì¸ í‰ê°€ 2~3ë¬¸ì¥]
""")
    
    # ì»¤ìŠ¤í…€ RAG ì²´ì¸ ìƒì„± (temperature íŒŒë¼ë¯¸í„° ì œê±°)
    evaluate_chain = build_custom_rag_chain(
    retriever, 
    prompt, 
    model_name="microsoft/DialoGPT-large"
)

    
    # ë¬¸ì œ ì¶”ì¶œ
    print("ğŸ“ ë¬¸ì œ ì¶”ì¶œ ì¤‘...")
    question_pdf_path = "toss_part3.pdf"
    loader = PyPDFLoader(question_pdf_path)
    pages = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, separators=["\n\n", "\n", ".", "?"])
    docs = splitter.split_documents(pages)
    
    questions = []
    for doc in docs:
        lines = doc.page_content.strip().split("\n")
        for line in lines:
            if line.strip().startswith("Q") and "?" in line:
                questions.append(line.strip())
    
    print(f"âœ… ì´ {len(questions)}ê°œì˜ ë¬¸ì œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
    
    # ë¬¸ì œ ë£¨í”„
    results = []
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ¯ [ë¬¸ì œ {i}] {question}")
        
        # ë¬¸ì œ ì½ì–´ì£¼ê¸°
        try:
            tts = gTTS(text=question, lang='en')
            filename = f"question_{i}.mp3"
            tts.save(filename)
            playsound.playsound(filename)
            os.remove(filename)
        except Exception as e:
            print(f"âš ï¸ TTS ì˜¤ë¥˜: {e}")
        
        # ìŒì„± ì…ë ¥ ë°›ê¸°
        user_answer = speech_to_text(15)
        print("ğŸ§  AI ì±„ì  ì¤‘...")
        
        try:
            # AI í‰ê°€
            evaluation = evaluate_chain({"question": question, "answer": user_answer})
            print("ğŸ’¡ AI í‰ê°€ ê²°ê³¼:\n", evaluation)
            
            results.append({"ë¬¸ì œ": question, "ë‹µë³€": user_answer, "ì±„ì ": evaluation})
            
        except Exception as e:
            print(f"âŒ í‰ê°€ ì˜¤ë¥˜: {e}")
            results.append({"ë¬¸ì œ": question, "ë‹µë³€": user_answer, "ì±„ì ": "í‰ê°€ ì‹¤íŒ¨"})
        
        input("[ì—”í„°] ë‹¤ìŒ ë¬¸ì œë¡œ...")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n===== ì „ì²´ ê²°ê³¼ ìš”ì•½ =====")
    for i, res in enumerate(results, 1):
        print(f"\n[ë¬¸ì œ {i}]: {res['ë¬¸ì œ']}")
        print(f"ğŸ—£ï¸ ë‹µë³€: {res['ë‹µë³€']}")
        print(f"ğŸ“Š AI í‰ê°€: {res['ì±„ì ']}")

if __name__ == "__main__":
    main()
