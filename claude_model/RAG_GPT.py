from dotenv import load_dotenv
load_dotenv()

import os
import torch
from transformers import pipeline
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import HuggingFacePipeline
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from example import speech_to_text
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from gtts import gTTS
import playsound

def build_custom_rag_chain(retriever, prompt, model_name="microsoft/DialoGPT-large", temperature=0):
    """ì»¤ìŠ¤í…€ RAG ì²´ì¸ ìƒì„± - RetrievalQA ë¬¸ì œ í•´ê²°"""
    
    print(f"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # Hugging Face íŒŒì´í”„ë¼ì¸ ìƒì„±
    hf_pipeline = pipeline(
        "text-generation",
        model=model_name,
        tokenizer=model_name,
        max_new_tokens=300,
        temperature=temperature,
        do_sample=True if temperature > 0 else False,
        device=0 if torch.cuda.is_available() else -1,
        pad_token_id=50256  # GPT ëª¨ë¸ìš© íŒ¨ë”© í† í°
    )
    
    # LangChain LLM ë˜í¼
    llm = HuggingFacePipeline(pipeline=hf_pipeline)
    
    # LLM ì²´ì¸ ìƒì„±
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    
    # ì»¤ìŠ¤í…€ RAG í•¨ìˆ˜
    def rag_chain(inputs):
        question = inputs["question"]
        answer = inputs["answer"]
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_query = f"{question} {answer}"
        docs = retriever.get_relevant_documents(search_query)
        context = "\n\n".join([doc.page_content for doc in docs[:3]])  # ìƒìœ„ 3ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
        
        # LLMì— ì „ë‹¬
        result = llm_chain.run(
            context=context,
            question=question,
            answer=answer
        )
        
        return result
    
    return rag_chain

def load_vectorstore():
    """ì €ì¥ëœ FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    db_path = "./db/faiss"
    
    if not os.path.exists(db_path):
        print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("ë¨¼ì € create_db.pyë¥¼ ì‹¤í–‰í•´ì„œ DBë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return None
    
    print("ğŸ” ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘...")
    # ì„ë² ë”© ëª¨ë¸ (DB ìƒì„±í•  ë•Œì™€ ë™ì¼í•´ì•¼ í•¨)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    
    # ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    print("âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì™„ë£Œ!")
    
    return vectorstore

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = load_vectorstore()
    if vectorstore is None:
        return
    
    retriever = vectorstore.as_retriever()
    
    # RAG ì²´ì¸ìš© í”„ë¡¬í”„íŠ¸ (ì»¤ìŠ¤í…€ ì²´ì¸ì— ë§ê²Œ ìˆ˜ì •)
    prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì˜ë¬¸ ë…í•´ ì‹œí—˜ì˜ í‰ê°€ìì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ˜í—˜ìƒì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ë¬¸ì œ: {question}
ìˆ˜í—˜ìƒ ë‹µë³€: {answer}

í‰ê°€ ê¸°ì¤€:
1. ìˆ˜í—˜ìƒì´ ì •ë‹µì— ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€
2. ë…¼ë¦¬ì  ê·¼ê±°ê°€ ì •í™•í•œì§€  
3. ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì˜ ë°˜ì˜í–ˆëŠ”ì§€

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
ì ìˆ˜: [1~5ì , ì†Œìˆ˜ì  ê°€ëŠ¥]
í”¼ë“œë°±: [í•œê¸€ë¡œ êµ¬ì²´ì ì¸ í‰ê°€ 2~3ë¬¸ì¥]
""")
    
    # ì»¤ìŠ¤í…€ RAG ì²´ì¸ ìƒì„±
    evaluate_chain = build_custom_rag_chain(
        retriever, 
        prompt, 
        model_name="microsoft/DialoGPT-large", 
        temperature=0
    )
    
    # ë¬¸ì œ ì¶”ì¶œ
    print("ğŸ“ ë¬¸ì œ ì¶”ì¶œ ì¤‘...")
    question_pdf_path = "toss_part3.pdf"
    loader = PyPDFLoader(question_pdf_path)
    pages = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, separators=["\n\n", "\n", ".", "?"])
    docs = splitter.split_documents(pages)
    
    questions = []
    for doc in docs:
        lines = doc.page_content.strip().split("\n")
        for line in lines:
            if line.strip().startswith("Q") and "?" in line:
                questions.append(line.strip())
    
    print(f"âœ… ì´ {len(questions)}ê°œì˜ ë¬¸ì œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
    
    # ë¬¸ì œ ë£¨í”„
    results = []
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ¯ [ë¬¸ì œ {i}] {question}")
        
        # ë¬¸ì œ ì½ì–´ì£¼ê¸°
        try:
            tts = gTTS(text=question, lang='en')
            filename = f"question_{i}.mp3"
            tts.save(filename)
            playsound.playsound(filename)
            os.remove(filename)
        except Exception as e:
            print(f"âš ï¸ TTS ì˜¤ë¥˜: {e}")
        
        # ìŒì„± ì…ë ¥ ë°›ê¸°
        user_answer = speech_to_text(15)
        print("ğŸ§  AI ì±„ì  ì¤‘...")
        
        try:
            # AI í‰ê°€ (ì»¤ìŠ¤í…€ ì²´ì¸ ì‚¬ìš©)
            evaluation = evaluate_chain({"question": question, "answer": user_answer})
            print("ğŸ’¡ AI í‰ê°€ ê²°ê³¼:\n", evaluation)
            
            # ê²°ê³¼ ì €ì¥
            results.append({"ë¬¸ì œ": question, "ë‹µë³€": user_answer, "ì±„ì ": evaluation})
            
        except Exception as e:
            print(f"âŒ í‰ê°€ ì˜¤ë¥˜: {e}")
            results.append({"ë¬¸ì œ": question, "ë‹µë³€": user_answer, "ì±„ì ": "í‰ê°€ ì‹¤íŒ¨"})
        
        input("[ì—”í„°] ë‹¤ìŒ ë¬¸ì œë¡œ...")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n===== ì „ì²´ ê²°ê³¼ ìš”ì•½ =====")
    for i, res in enumerate(results, 1):
        print(f"\n[ë¬¸ì œ {i}]: {res['ë¬¸ì œ']}")
        print(f"ğŸ—£ï¸ ë‹µë³€: {res['ë‹µë³€']}")
        print(f"ğŸ“Š AI í‰ê°€: {res['ì±„ì ']}")

if __name__ == "__main__":
    main()
