import gradio as gr
import os
import tempfile
from dotenv import load_dotenv
from gtts import gTTS

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from gpt4o_evaluate import gpt4o_evaluate
from claude_API import build_claude_chain
from text2speech import speech_to_text  # ë°˜ë“œì‹œ íŒŒì¼ë¡œë¶€í„°(stt) ì¸ì‹í•˜ëŠ” êµ¬ì¡°ë¡œ ë˜ì–´ ìžˆì–´ì•¼ í•¨
from claude_direct_evaluate import claude_direct_evaluate
from gpt_chain import build_gpt_chain
load_dotenv()

vectorstore = None
questions = []
question_choices = []  # ì„ íƒì§€ ì €ìž¥ìš© ë¦¬ìŠ¤íŠ¸ë„ ì¶”ê°€
logs = []
question_index = 0
evaluate_chain = None
gpt_evaluate_chain = None  # ì „ì—­ì— ì¶”ê°€

def load_vectorstore():
    global vectorstore
    db_path = "./db/faiss"
    if not os.path.exists(db_path):
        return "âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    return "âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì™„ë£Œ!"
def preview_vectorstore_contents():
    global vectorstore
    if vectorstore is None:
        return "âŒ ë¨¼ì € ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”."

    try:
        # FAISSëŠ” ê¸°ë³¸ì ìœ¼ë¡œ vectorsë§Œ ì €ìž¥í•˜ê³ , metadataë¡œë¶€í„° ë¬¸ì„œ ë‚´ìš©ì„ ì¼ë¶€ í™•ì¸í•  ìˆ˜ ìžˆìŒ
        docs = vectorstore.similarity_search("TOEIC Speaking Proficiency Level Descriptors", k=5)  # ì•„ë¬´ ì§ˆì˜ì–´ ë„£ê³  ìƒìœ„ 5ê°œ ê²€ìƒ‰
        if not docs:
            return "â— ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        output = "ðŸ” ë²¡í„°ìŠ¤í† ì–´ ë¯¸ë¦¬ë³´ê¸°:\n"
        for i, doc in enumerate(docs):
            content = doc.page_content.strip().replace("\n", " ")[:150]
            output += f"{i+1}. {content}...\n"
        return output

    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def extract_questions(pdf_file):
    global questions, question_choices, question_index
    if pdf_file is None:
        return "âŒ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    pdf_path = pdf_file.name
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, separators=["\n\n", "\n", ".", "?"])
    docs = splitter.split_documents(pages)

    extracted = []
    choices = []
    for doc in docs:
        lines = doc.page_content.strip().split("\n")
        current_q = None
        current_choices = []
        for line in lines:
            stripped = line.strip()
            if stripped.startswith("Q") and "?" in stripped:
                if current_q:
                    extracted.append(current_q)
                    choices.append(current_choices)
                current_q = stripped
                current_choices = []
            elif stripped.startswith("-") and current_q:
                current_choices.append(stripped)
        if current_q:
            extracted.append(current_q)
            choices.append(current_choices)
    questions = extracted
    question_choices = choices
    question_index = 0
    return f"âœ… ì´ {len(questions)}ê°œì˜ ë¬¸ì œê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤."


def setup_chain():
    global evaluate_chain, gpt_evaluate_chain, vectorstore
    if vectorstore is None:
        return "â— ë¨¼ì € ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”."
    retriever = vectorstore.as_retriever()
    prompt = PromptTemplate.from_template("""
    ë„ˆëŠ” ì˜ë¬¸ ë…í•´ ì‹œí—˜ì˜ í‰ê°€ìžë‹¤. ì•„ëž˜ ë¬¸ì œ, ë‹µë³€, context(ë¬¸ì„œì˜ ì¼ë¶€)ê°€ ìžˆë‹¤.

#Question: {question}
#Answer: {answer}
#Context: {context}
- í† ìµìŠ¤í”¼í‚¹ì˜ ì±„ì  ê¸°ì¤€ì„ ë§í•´ë¼.
- ìˆ˜í—˜ìƒì´ ì •ë‹µì— ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€, ë…¼ë¦¬ì  ê·¼ê±°ê°€ ì •í™•í•œì§€ 'contextë§Œ í™œìš©'í•´ì„œ í•œê¸€ë¡œ 5ë¬¸ìž¥ í‰ê°€Â·ì ìˆ˜(level1~8, ì†Œìˆ˜ì  í—ˆìš©)ë¡œ ì±„ì í•˜ë¼.
- ë‹¤ìŒ í‰ê°€ í•­ëª©ë³„ë¡œ ì ê²€í•˜ë˜, ë°˜ë“œì‹œ 5ë¬¸ìž¥(ë¬¸ìž¥ë³„ 2ì¤„ ì´í•˜, ê°„ê²°í•˜ê²Œ)ìœ¼ë¡œ í•œê¸€ë¡œ ìž‘ì„±í•˜ë¼:
  1. ì •ë‹µí¬ì¸íŠ¸ í¬í•¨ ì—¬ë¶€ ë° ì •í™•ì„±
  2. ë…¼ë¦¬ ì „ê°œì™€ ê·¼ê±° í™œìš©
  3. ë§¥ë½(ë¬¸ì„œ ë‚´ìš©)ê³¼ì˜ ì¼ì¹˜ë„
  4. ì–´íœ˜/ë¬¸ë²•(í‹€ë¦° ë¶€ë¶„ ê°„ë‹¨ížˆ ì§€ì )
  5. ê°œì„  ë˜ëŠ” ë³´ì™„ì , ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
- ë§ˆì§€ë§‰ ë¬¸ìž¥ì—ëŠ” ë°˜ë“œì‹œ [ì ìˆ˜: level x] í˜•ì‹(level1~8, 0.5ë‹¨ìœ„)ìœ¼ë¡œ ë¶€ì—¬í•˜ê³ , ì ìˆ˜ ë¶€ì—¬ ì´ìœ ë¥¼ ë¶„ëª…ížˆ ëª…ì‹œí•˜ë¼.
- ë¶ˆì¶©ë¶„í•œ ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ êµ¬ì²´ì  ê°œì„ ì‚¬í•­ì„ ì ëŠ”ë‹¤.


[ì¶œë ¥ ì˜ˆì‹œ]
1. ë‹µë³€ì— contextì˜ í•µì‹¬ ë‚´ìš©ì„ ì •í™•ížˆ ë°˜ì˜í•˜ì˜€ë‹¤.  
2. ë…¼ë¦¬ê°€ ì¼ê´€ë˜ê³ , ê·¼ê±° ì œì‹œê°€ ëª…í™•í•˜ë‹¤.  
3. ë¬¸ì„œì˜ ì„¸ë¶€ë‚´ìš©ê³¼ ë¶€í•©í•œë‹¤.  
4. ì–´íœ˜ì™€ ë¬¸ë²• ì‹¤ìˆ˜ëŠ” ê±°ì˜ ì—†ë‹¤.  
5. ë‹¤ë§Œ, ì˜ˆì‹œë¥¼ í•œ ê°€ì§€ ì¶”ê°€í•˜ë©´ ë” ì¢‹ê² ë‹¤.  
ë ˆë²¨: level 1~8
    """)
    evaluate_chain = build_claude_chain(retriever, prompt, model_name="claude-3-haiku-20240307", temperature=0)
    gpt_evaluate_chain = build_gpt_chain(retriever, prompt, model_name='gpt-4o', temperature=0)  # âœ… ì¶”ê°€
    return "âœ… í‰ê°€ ì²´ì¸ ì¤€ë¹„ ì™„ë£Œ!"

def get_next_question():
    global question_index
    if not questions:
        return "â— ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", None, None
    if question_index >= len(questions):
        return "ðŸŽ‰ ëª¨ë“  ë¬¸ì œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!", None, None

    question = questions[question_index]
    choices = question_choices[question_index] if question_index < len(question_choices) else []
    question_index += 1

    combined_text = question
    if choices:
        combined_text += "\n\n[ì„ íƒì§€]\n" + "\n".join(choices)

    # TTSìš© í…ìŠ¤íŠ¸ë„ ë¬¸ì œ + ì„ íƒì§€ë¡œ
    tts = gTTS(text=combined_text, lang='en')
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(tmp.name)
    tmp.close()

    return f"[ë¬¸ì œ {question_index}] {combined_text}", tmp.name, ""  # <- choice_outputì€ ì´ì œ ê³µë°± ì²˜ë¦¬


def go_to_previous_question():
    global question_index
    if question_index <= 1:
        return "âš ï¸ ì²« ë²ˆì§¸ ë¬¸ì œìž…ë‹ˆë‹¤.", None, None
    question_index -= 1
    question = questions[question_index - 1]
    choices = question_choices[question_index - 1] if question_index - 1 < len(question_choices) else []

    combined_text = question
    if choices:
        combined_text += "\n\n[ì„ íƒì§€]\n" + "\n".join(choices)

    tts = gTTS(text=combined_text, lang='en')
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(tmp.name)
    tmp.close()

    return f"[ë¬¸ì œ {question_index}] {combined_text}", tmp.name, ""

def evaluate_audio_response(audio):
    global question_index, evaluate_chain, logs
    if evaluate_chain is None:
        return "âŒ í‰ê°€ ì²´ì¸ì„ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.", "", ""

    if question_index == 0:
        return "â— ë¬¸ì œë¥¼ ë¨¼ì € ì‹œìž‘í•´ì£¼ì„¸ìš”.", "", ""

    question = questions[question_index - 1]
    user_answer = speech_to_text(audio)
    context_docs = vectorstore.similarity_search(question, k=3)
    context = "\n".join([doc.page_content for doc in context_docs])

    claude_chain_result = evaluate_chain.invoke({"question": question, "answer": user_answer})
    gpt_chain_result = gpt_evaluate_chain.invoke({"question": question, "answer": user_answer})
    gpt_result = gpt4o_evaluate(question, user_answer, context)
    claude_direct_result = claude_direct_evaluate(question, user_answer, context)

    def extract_score(text):
        import re
        match = re.search(r"ì ìˆ˜:\s*([0-9.]+)ì ", text)
        return float(match.group(1)) if match else None

    score_claude_chain = extract_score(claude_chain_result)
    score_claude_direct = extract_score(claude_direct_result)
    score_gpt = extract_score(gpt_result)
    score_gpt_chain = extract_score(gpt_chain_result)

    logs.append({
        "question_index": question_index,
        "question": question,
        "answer_text": user_answer,
        "audio_path": audio,
        "claude_chain_result": claude_chain_result,
        "claude_direct_result": claude_direct_result,
        "gpt_chain_result": gpt_chain_result,
        "gpt_direct_result": gpt_result,
        "score_claude_chain": score_claude_chain,
        "score_claude_direct": score_claude_direct,
        "score_gpt_chain": score_gpt_chain,
        "score_gpt_direct": score_gpt,
    })


    combined_result = f"""ðŸ§  Claude (LangChain ê¸°ë°˜) í‰ê°€ ê²°ê³¼:
{claude_chain_result}

ðŸ§  Claude (ì§ì ‘ í˜¸ì¶œ) í‰ê°€ ê²°ê³¼:
{claude_direct_result}

ðŸ¤– GPT-4o (LangChain ê¸°ë°˜) í‰ê°€ ê²°ê³¼:
{gpt_chain_result}

ðŸ¤– GPT-4o (ì§ì ‘ í˜¸ì¶œ) í‰ê°€ ê²°ê³¼:
{gpt_result}
"""

    return combined_result, user_answer, gpt_result
import json

def save_logs_to_file(path="logs.json"):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)

def load_logs_from_file(path="logs.json"):
    global logs
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            logs = json.load(f)

with gr.Blocks() as demo:
    with gr.Tab("ë¬¸ì œí’€ì´"):
        gr.Markdown("## ðŸ—£ï¸ í† ìµìŠ¤í”¼í‚¹ AI ì±„ì  ì‹œìŠ¤í…œ")

        with gr.Row():
            pdf_input = gr.File(label="ðŸ“„ ë¬¸ì œ PDF ì—…ë¡œë“œ", file_types=[".pdf"])
            upload_result = gr.Textbox(label="ë¬¸ì œ ì¶”ì¶œ ê²°ê³¼")

        with gr.Row():
            load_btn = gr.Button("ðŸ“‚ ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸°")
            vectorstore_status = gr.Textbox(label="ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ")
        # with gr.Row():
        #     scoring_btn = gr.Button("ðŸ“‹ í† ìµìŠ¤í”¼í‚¹ ì±„ì  ê¸°ì¤€ ë³´ê¸°")
        #     scoring_output = gr.Textbox(label="ðŸ“Œ ì±„ì  ê¸°ì¤€ ì¶œë ¥", lines=10)

        with gr.Row():
            setup_btn = gr.Button("ðŸ§  í‰ê°€ ì²´ì¸ ì¤€ë¹„")
            chain_status = gr.Textbox(label="í‰ê°€ ì²´ì¸ ìƒíƒœ")

        with gr.Row():
            next_q_btn = gr.Button("ðŸ“¢ ë‹¤ìŒ ë¬¸ì œ")
            prev_q_btn = gr.Button("âª ì´ì „ ë¬¸ì œ")
        with gr.Row():
            preview_btn = gr.Button("ðŸ”Ž ë²¡í„°ìŠ¤í† ì–´ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°")
            preview_output = gr.Textbox(label="ðŸ“š ë²¡í„°ìŠ¤í† ì–´ ë¯¸ë¦¬ë³´ê¸°", lines=6)
        question_output = gr.Textbox(label="ë¬¸ì œ ë³´ê¸°")
        question_audio = gr.Audio(label="ë¬¸ì œ ìŒì„±", type="filepath")
        # choice_output = gr.Textbox(label="ì„ íƒì§€ ë³´ê¸°", lines=3, interactive=False)  # ì´ ì¤„ ì¶”ê°€
        

        audio_input = gr.Audio(label="ðŸŽ¤ ìŒì„± ë‹µë³€", type="filepath")
        user_transcript = gr.Textbox(label="ðŸ“ ì¸ì‹ëœ ë‹µë³€ (í…ìŠ¤íŠ¸)", interactive=False)
        result_output = gr.Textbox(label="ðŸ“Š AI í‰ê°€ ê²°ê³¼ (Claude + GPT)", lines=6)
        # gpt_output = gr.Textbox(label="ðŸ¤– GPT-4o í‰ê°€ ê²°ê³¼ë§Œ ë³´ê¸°", lines=4)

        # scoring_btn.click(fn=show_scoring_criteria, outputs=[scoring_output])
        pdf_input.change(fn=extract_questions, inputs=[pdf_input], outputs=[upload_result])
        load_btn.click(fn=load_vectorstore, outputs=[vectorstore_status])
        setup_btn.click(fn=setup_chain, outputs=[chain_status])
        next_q_btn.click(fn=get_next_question, outputs=[question_output, question_audio])
        prev_q_btn.click(fn=go_to_previous_question, outputs=[question_output, question_audio])
        audio_input.change(fn=evaluate_audio_response, inputs=[audio_input],
                        outputs=[result_output, user_transcript])
        preview_btn.click(fn=preview_vectorstore_contents, outputs=[preview_output])
        
#     with gr.Tab("ë‹µë³€ ë¡œê·¸ ë³´ê¸°"):
#         # ë¡œê·¸ ì¶œë ¥ UI ë° ì‹œê°í™” ë°°ì¹˜
#         log_text = gr.Textbox(label="ë‹µë³€ ë¡œê·¸", lines=10)
#         audio_list = gr.Dropdown(label="ë…¹ìŒ íŒŒì¼ ì„ íƒ")
#         audio_player = gr.Audio(label="ë…¹ìŒ ìž¬ìƒ", type="filepath")
#         plot_output = gr.Plot(label="ì ìˆ˜ ì¶”ì´")

#         # ë¡œê·¸ í…ìŠ¤íŠ¸ ë³´ì—¬ì£¼ê¸°
#         def get_log_text():
#             if not logs:
#                 return "ë‹µë³€ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
#             lines = []
#             for log in logs:
#                 lines.append(f"Q{log['question_index']}: {log['question']}")
#                 lines.append(f"ë‹µë³€: {log['answer_text']}")
#                 lines.append(f"""
#                 Claude(ì²´ì¸): {log.get('score_claude_chain')}
#                 Claude(ì§ì ‘): {log.get('score_claude_direct')}
#                 GPT-4o(ì²´ì¸): {log.get('score_gpt_chain')}
#                 GPT-4o(ì§ì ‘): {log.get('score_gpt_direct')}
#                 """.strip())
#                 lines.append("------")
#             return "\n".join(lines)

#         def update_audio_list():
#             return [log['audio_path'] for log in logs]

#         def play_audio(file_path):
#             return file_path

#         import matplotlib.pyplot as plt
#         import numpy as np
#         def plot_scores():
#             if not logs:
#                 fig, ax = plt.subplots()
#                 ax.set_title("ì ìˆ˜ ì—†ìŒ")
#                 return fig

#             x = [log["question_index"] for log in logs if log["score_claude_chain"] is not None]
#             y_claude_chain = [log["score_claude_chain"] for log in logs if log["score_claude_chain"] is not None]
#             y_claude_direct = [log["score_claude_direct"] for log in logs if log["score_claude_direct"] is not None]
#             y_gpt_chain = [log["score_gpt_chain"] for log in logs if log["score_gpt_chain"] is not None]
#             y_gpt_direct = [log["score_gpt_direct"] for log in logs if log["score_gpt_direct"] is not None]

#             fig, ax = plt.subplots()
#             ax.plot(x, y_claude_chain, label="Claude ì²´ì¸", marker="o")
#             ax.plot(x, y_claude_direct, label="Claude ì§ì ‘", marker="s")
#             ax.plot(x, y_gpt_chain, label="GPT ì²´ì¸", marker="^")
#             ax.plot(x, y_gpt_direct, label="GPT ì§ì ‘", marker="x")
#             ax.set_xlabel("ë¬¸ì œ ë²ˆí˜¸")
#             ax.set_ylabel("ì ìˆ˜")
#             ax.set_title("ëª¨ë¸ë³„ ì ìˆ˜ ë¹„êµ")
#             ax.legend()
#             ax.grid(True)
#             return fig



#         show_log_btn = gr.Button("ë¡œê·¸ ìƒˆë¡œê³ ì¹¨")
#         show_log_btn.click(get_log_text, outputs=[log_text])
#         show_log_btn.click(update_audio_list, outputs=[audio_list])

#         audio_list.change(play_audio, inputs=[audio_list], outputs=[audio_player])
#         show_log_btn.click(plot_scores, outputs=[plot_output])
# # ë²„íŠ¼ ê¸°ëŠ¥ ì—°ê²°
    
    


demo.launch()
