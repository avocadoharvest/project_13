from dotenv import load_dotenv
load_dotenv()

import os
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

def create_and_save_vectorstore():
    """PDFë¥¼ ë¡œë“œí•˜ê³  FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•´ì„œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    
    print("ğŸ“– PDF ë¡œë”© ì¤‘...")
    # PDF ë¡œë“œ
    loader = PyMuPDFLoader("toeic.pdf")
    pages = loader.load_and_split()
    
    print("âœ‚ï¸ ë¬¸ì„œ ë¶„í•  ì¤‘...")
    # ë¬¸ì„œ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)
    chunks = splitter.split_documents(pages)
    
    print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
    # ì„ë² ë”© ëª¨ë¸
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    
    print("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    # FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(documents=chunks, embedding=embeddings)
    
    # DB ë””ë ‰í„°ë¦¬ ìƒì„±
    db_path = "./db/faiss"
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    
    print("ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì¤‘...")
    # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥
    vectorstore.save_local(db_path)
    
    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ê°€ {db_path}ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“Š ì´ {len(chunks)}ê°œì˜ ì²­í¬ê°€ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    create_and_save_vectorstore()
