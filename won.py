# from langchain.document_loaders import PyPDFLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter

# # 1. PDF ë¡œë“œ
# loader = PyPDFLoader("C:\_vscode\Chap.03\knudata\project_13\í† ìŠ¤ íŒŒíŠ¸ 3 ë¬¸ì œ.pdf")
# pages = loader.load()

# # 2. í…ìŠ¤íŠ¸ ì²­í¬ ë‚˜ëˆ„ê¸° (ë¬¸ì œ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ë˜ê²Œ ê¸°ì¤€ ì¡°ì •)
# splitter = RecursiveCharacterTextSplitter(
#     chunk_size=500,
#     chunk_overlap=50,
#     separators=["\n\n", "\n", ".", "?"]
# )
# docs = splitter.split_documents(pages)

# # 3. ì¶œë ¥ í™•ì¸
# for i, doc in enumerate(docs[:5]):
#     print(f"[ë¬¸ì œ {i+1}]\n", doc.page_content)

# from langchain_community.document_loaders import PyPDFLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# import whisper
# import speech_recognition as sr
# import numpy as np

# # ===== 1. PDFì—ì„œ ë¬¸ì œ ì¶”ì¶œ =====
# pdf_path = r"C:\_vscode\Chap.03\knudata\project_13\í† ìŠ¤ íŒŒíŠ¸ 3 ë¬¸ì œ.pdf"
# loader = PyPDFLoader(pdf_path)
# pages = loader.load()

# splitter = RecursiveCharacterTextSplitter(
#     chunk_size=500,
#     chunk_overlap=50,
#     separators=["\n\n", "\n", ".", "?"]
# )
# docs = splitter.split_documents(pages)

# questions = []
# for doc in docs:
#     lines = doc.page_content.strip().split("\n")
#     for line in lines:
#         if line.startswith("Q") and "?" in line:
#             questions.append(line.strip())

# # ===== 2. Whisper + Mic ì¤€ë¹„ =====
# model = whisper.load_model("base")
# r = sr.Recognizer()

# # ===== 3. ë°˜ë³µ: ë¬¸ì œ ë³´ì—¬ì£¼ê³  ë§ˆì´í¬ë¡œ ë°›ê¸° =====
# for i, question in enumerate(questions, 1):
#     print(f"\nğŸ¯ [ë¬¸ì œ {i}] {question}")
#     print("ğŸ¤ ë‹µë³€ì„ ë§í•´ì£¼ì„¸ìš”...")

#     with sr.Microphone(sample_rate=16000) as source:
#         audio = r.listen(source)
#         data = audio.get_wav_data()

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import whisper
import speech_recognition as sr
import numpy as np

def run_toeic_part3_stt(pdf_path: str):
    # ===== 1. PDFì—ì„œ ë¬¸ì œ ì¶”ì¶œ =====
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", ".", "?"]
    )
    docs = splitter.split_documents(pages)

    questions = []
    for doc in docs:
        lines = doc.page_content.strip().split("\n")
        for line in lines:
            if line.startswith("Q") and "?" in line:
                questions.append(line.strip())

    # ===== 2. Whisper + Mic ì¤€ë¹„ =====
    model = whisper.load_model("base")
    r = sr.Recognizer()

    # ===== 3. ë°˜ë³µ: ë¬¸ì œ ë³´ì—¬ì£¼ê³  ë§ˆì´í¬ë¡œ ë°›ê³  ê²°ê³¼ ì €ì¥ =====
    results = []
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ¯ [ë¬¸ì œ {i}] {question}")
        print("ğŸ¤ ë‹µë³€ì„ ë§í•´ì£¼ì„¸ìš”...")

        with sr.Microphone(sample_rate=16000) as source:
            audio = r.listen(source)
            data = audio.get_wav_data()
            wav = np.frombuffer(data, np.int16).astype(np.float32) / 32768.0

            print("ğŸ§  ìŒì„± ì¸ì‹ ì¤‘...")
            result = model.transcribe(wav, fp16=False)
            print("ğŸ“ ì¸ì‹ëœ ë‹µë³€:", result["text"])
            results.append((question, result["text"]))

        input("ğŸ‘‰ [ì—”í„°]ë¥¼ ëˆ„ë¥´ë©´ ë‹¤ìŒ ë¬¸ì œë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")

    return results


if __name__ == "__main__":
    pdf_path = r"C:\_vscode\Chap.03\knudata\project_13\í† ìŠ¤ íŒŒíŠ¸ 3 ë¬¸ì œ.pdf"
    results = run_toeic_part3_stt(pdf_path)

    print("\nğŸ¯ ëª¨ë“  ë‹µë³€ ê²°ê³¼ ìš”ì•½:")
    for i, (q, a) in enumerate(results, 1):
        print(f"\n[ë¬¸ì œ {i}] {q}")
        print(f"ğŸ—£ï¸ ë‹µë³€: {a}")
